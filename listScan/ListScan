// MP Scan
// Given a list (lst) of length n
// Output its prefix sum = {lst[0], lst[0] + lst[1], lst[0] + lst[1] + ... + lst[n-1]}

#include    <wb.h>
#define BLOCK_SIZE 512

#define wbCheck(stmt) do {                                                    \
        cudaError_t err = stmt;                                               \
        if (err != cudaSuccess) {                                             \
            wbLog(ERROR, "Failed to run stmt ", #stmt);                       \
            wbLog(ERROR, "Got CUDA error ...  ", cudaGetErrorString(err));    \
            return -1;                                                        \
        }                                                                     \
    } while(0)


    
__global__ void scan(float * input, float * output, int len,float * S) {
    //@@ Modify the body of this function to complete the functionality of
    //@@ the scan on the device
    //@@ You may need multiple kernel calls; write your kernels before this
    //@@ function and call them from here
	
	
	__shared__ float XY[BLOCK_SIZE];
	int stride = 0;
	
	int i = blockIdx.x*blockDim.x + threadIdx.x;
	if(i<len)
	{
	    XY[threadIdx.x] = input[i];	
	}
	
	for(stride =1;stride <= blockDim.x;stride *= 2)
	{
		__syncthreads();
		int index = (threadIdx.x + 1)*stride*2 - 1;
		if(index < blockDim.x)
		{
			XY[index] += XY[index - stride];
			
		}
		
		
		
	}
	
	int stride1 = 0;
	for(stride1 = BLOCK_SIZE/2;stride1 > 0;stride1 /=2)
	{
		__syncthreads();
		int index1 =  (threadIdx.x + 1)*stride1*2 - 1;
		if(index1 + stride1 < BLOCK_SIZE)
		{
		   XY[index1 + stride1] += XY[index1]	;
		}
	}
	__syncthreads();
	
	if(i < len)
	{
		output[i] = XY[threadIdx.x];
		
	}
	
	__syncthreads();
	
	if(threadIdx.x == 0)
	{
		S[blockIdx.x] = XY[BLOCK_SIZE - 1];
		
	}
}

__global__ void scan1(float * input, int len) {
    //@@ Modify the body of this function to complete the functionality of
    //@@ the scan on the device
    //@@ You may need multiple kernel calls; write your kernels before this
    //@@ function and call them from here
	
	
	//shared__ float XY[BLOCK_SIZE];
	int stride = 0;
	
	int i = blockIdx.x*blockDim.x + threadIdx.x;
	if(i<len)
	{
	  //  XY[threadIdx.x] = input[i];	
	}
	
	for(stride =1;stride <= blockDim.x;stride *= 2)
	{
		__syncthreads();
		int index = (threadIdx.x + 1)*stride*2 - 1;
		if(index < blockDim.x)
		{
			input[index] += input[index - stride];
			
		}
		
		
		
	}
	
	int stride1 = 0;
	for(stride1 = BLOCK_SIZE/2;stride1 > 0;stride1 /=2)
	{
		__syncthreads();
		int index1 =  (threadIdx.x + 1)*stride1*2 - 1;
		if(index1 + stride1 < BLOCK_SIZE)
		{
		   input[index1 + stride1] += input[index1]	;
		}
	}
	__syncthreads();
	
	
	
	
}


__global__ void scan2(float * input, float *S) {
    //@@ Modify the body of this function to complete the functionality of
    //@@ the scan on the device
    //@@ You may need multiple kernel calls; write your kernels before this
    //@@ function and call them from here
	
	
	
	
	int i = blockIdx.x*blockDim.x + threadIdx.x;
	if(blockIdx.x > 0)
	{
	    input[i] += S[blockIdx.x - 1];		
	}
	
	
	
}

int main(int argc, char ** argv) {
    wbArg_t args;
    float * hostInput; // The input 1D list
    float * hostOutput; // The output list
    float * deviceInput;
    float * deviceOutput;
	float * hostS;
	float * deviceS;
    int numElements; // number of elements in the list

    args = wbArg_read(argc, argv);
	
    wbTime_start(Generic, "Importing data and creating memory on host");
    hostInput = (float *) wbImport(wbArg_getInputFile(args, 0), &numElements);
    hostOutput = (float*) malloc(numElements * sizeof(float));
	int Ssize = ((numElements-1)/BLOCK_SIZE)+1;

	hostS = (float*) malloc(Ssize* sizeof(float));
    wbTime_stop(Generic, "Importing data and creating memory on host");

    wbLog(TRACE, "The number of input elements in the input is ", numElements);

    wbTime_start(GPU, "Allocating GPU memory.");
    wbCheck(cudaMalloc((void**)&deviceInput, numElements*sizeof(float)));
    wbCheck(cudaMalloc((void**)&deviceOutput, numElements*sizeof(float)));
	cudaMalloc((void**)&deviceS, Ssize*sizeof(float));
    wbTime_stop(GPU, "Allocating GPU memory.");

    wbTime_start(GPU, "Clearing output memory.");
    wbCheck(cudaMemset(deviceOutput, 0, numElements*sizeof(float)));
	cudaMemset(deviceS, 0, Ssize*sizeof(float));
    wbTime_stop(GPU, "Clearing output memory.");

    wbTime_start(GPU, "Copying input memory to the GPU.");
    wbCheck(cudaMemcpy(deviceInput, hostInput, numElements*sizeof(float), cudaMemcpyHostToDevice));
    wbTime_stop(GPU, "Copying input memory to the GPU.");

    //@@ Initialize the grid and block dimensions here

    wbTime_start(Compute, "Performing CUDA computation");
    //@@ Modify this to complete the functionality of the scan
    //@@ on the deivce
	
	int i=0;
	
	wbLog(TRACE,"Ssie is",Ssize);
	wbLog(TRACE,"512th element ",hostInput[512]);
	
	
	
	scan<<<Ssize,BLOCK_SIZE>>>(deviceInput,deviceOutput,numElements,deviceS);
	
	cudaMemcpy(hostS, deviceS, Ssize*sizeof(float), cudaMemcpyDeviceToHost);
	cudaMemcpy(hostOutput, deviceOutput, numElements*sizeof(float), cudaMemcpyDeviceToHost);
	cudaMemcpy(deviceS, hostS, Ssize*sizeof(float), cudaMemcpyHostToDevice);
	cudaMemcpy(deviceOutput, hostOutput, numElements*sizeof(float), cudaMemcpyHostToDevice);
	
	wbLog(TRACE,"511 output",hostOutput[511]);
	wbLog(TRACE,"995 output", hostOutput[995]);
	wbLog(TRACE,"999 output", hostOutput[999]);
	
	for(i=0;i<Ssize;i++)
	{
		wbLog(TRACE, hostS[i]);
		
	}
	
    scan1<<<1,Ssize>>>(deviceS,Ssize);
	cudaMemcpy(hostS, deviceS, Ssize*sizeof(float), cudaMemcpyDeviceToHost);
	cudaMemcpy(deviceS, hostS, Ssize*sizeof(float), cudaMemcpyHostToDevice);
	
	
	scan2<<<Ssize,BLOCK_SIZE>>>(deviceOutput,deviceS);
	
	
    cudaDeviceSynchronize();
    wbTime_stop(Compute, "Performing CUDA computation");

    wbTime_start(Copy, "Copying output memory to the CPU");
    wbCheck(cudaMemcpy(hostOutput, deviceOutput, numElements*sizeof(float), cudaMemcpyDeviceToHost));
    wbTime_stop(Copy, "Copying output memory to the CPU");

    wbTime_start(GPU, "Freeing GPU Memory");
    cudaFree(deviceInput);
    cudaFree(deviceOutput);
    wbTime_stop(GPU, "Freeing GPU Memory");

    wbSolution(args, hostOutput, numElements);

    free(hostInput);
    free(hostOutput);

    return 0;
}

